article:
- author: Deleforge, Antoine and Di Carlo, Diego and Strauss, Martin and Serizel,
    Romain and Marcenaro, Lucio
  journal: IEEE Signal Processing Magazine
  keywords: Blind Channel Identification, Super Resolution, Sparsity, Acoustic Impulse Response.
  number: 5
  pages: 138--144
  publisher: IEEE
  title: >
    Audio-Based Search and Rescue With a Drone: Highlights From the IEEE Signal
    Processing Cup 2019 Student Competition
  volume: 36
  year: 2019
  doi: https://doi.org/10.1109/MSP.2019.2924687
  resources_link:
    - name: IEEE
      icon: ai ai-doi
      link: https://doi.org/10.1109/MSP.2019.2924687
    - name: Github
      icon: fa fa-github
      link: https://github.com/Chutlhu/SPCUP19
  resources_popup:
    - name: Bibtex
      icon: fa fa-quote-right
      link: www.notdefinedyet.com
      text: >
        @article{Deleforge2019audio,
          author = {Deleforge, Antoine and {Di Carlo}, Diego and Strauss, Martin and Serizel, Romain and Marcenaro, Lucio},
          journal = {IEEE Signal Processing Magazine},
          number = {5},
          pages = {138--144},
          publisher = {IEEE},
          title = {Audio-Based Search and Rescue With a Drone: Highlights From the IEEE Signal Processing Cup 2019 Student Competition [SP Competitions]},
          url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827999},
          volume = {36},
          year = {2019}
        }
    - name: Abstract
      icon: fa fa-align-left
      link: www.notdefinedyet.com
      text: >
        Increasing interest in unmanned aerial vehicles (UAVs), commonly referred to as drones, has occurred in recent years.
        Search and rescue scenarios where humans in emergency situations need to be quickly found in difficult to access areas constitute
        an important field of application for this technology.
        Drones have already been used by humanitarian organizations in countries such as Haiti and
        the Philippines to map areas after a natural disaster using high-resolution embedded cameras,
        as documented in a recent United Nations report [1].
        Although research efforts have focused mostly on developing video-based solutions for this task [2],
        UAV-embedded audio-based localization has received relatively less attention [3-7].
        However, UAVs equipped with a microphone array could be of critical help to localize people in emergency situations,
        especially when video sensors are limited by a lack of visual feedback due to bad lighting conditions
        (such as at night or in fog) or obstacles limiting the field of view (Figure 1).



inproceedings:
- title: 'BLASTER: An Off-Grid Method for Blind and Regularized Acoustic Echoes Retrieval'
  id: blaster
  author: 'Di Carlo, Diego and Elvira, Clement  and Deleforge, Antoine and Bertin, Nancy and Gibonval, Remi'
  booktitle: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  keywords: Blind Channel Identification, Super Resolution, Sparsity, Acoustic Impulse Response.
  year: 2020
  doi: https://doi.org/10.1109/ICASSP40776.2020.9054647
  resources_link:
    - name: IEEE
      icon: ai ai-doi
      link: https://doi.org/10.1109/ICASSP40776.2020.9054647
    - name: HAL
      icon: ai ai-open-access
      link: https://hal.archives-ouvertes.fr/hal-02469901/
    - name: Code
      icon: fa fa-github
      link: https://gitlab.inria.fr/panama-team/blaster
    - name: Resources
      icon: fa fa-paperclip
      link: https://sigport.org/documents/blaster-grid-method-blind-and-regularized-acoustic-echoes-retrieval
    - name: Video
      icon: fa fa-youtube-play
      link: https://youtu.be/rPaqZJIfpKo
  resources_popup:
    - name: Bibtex
      icon: fa fa-quote-right
      text: >
        @inproceedings{dicarlo2020blaster,
        author={Diego {Di Carlo} and Clement {Elvira} and Antoine {Deleforge} and Nancy {Bertin} and Remi {Gribonval}},
        booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
        title={Blaster: An Off-Grid Method for Blind and Regularized Acoustic Echoes Retrieval},
        year={2020},
        volume={},
        number={},
        pages={156-160}
        }
    - name: Abstract
      icon: fa fa-align-left
      text: >
        Acoustic echoes retrieval is a research topic that is gaining importance
        in many speech and audio signal processing applications such as speech enhancement,
        source separation, dereverberation and room geometry estimation.
        This work proposes a novel approach to retrieve acoustic echoes timing *off-grid* and blindly,
        i.e., from a stereophonic recording of an unknown sound source such as speech.
        It builds on the recent framework of continuous dictionaries.
        In contrast with existing methods, the proposed approach does not
        rely on parameter tuning nor peak picking techniques by working directly
        in the parameter space of interest. The accuracy and robustness of
        the method are assessed on challenging simulated setups with
        varying noise and reverberation levels and are compared to two state-of-the-art methods.

- title: 'MIRAGE: 2D Source Localization Using Microphone Pair Augmentation with Echoes'
  id: mirage
  author: ' Di Carlo, Diego and Deleforge, Antoine and Bertin, Nancy'
  booktitle: IEEE International Conference on Acoustics, Speech and Signal Processing
  keywords: Image Microphones,Sound Source Localization,Supervised Learning,TDOA Estimation
  year: 2019
  doi: https://doi.org/10.1109/ICASSP.2019.8683534
  resources_link:
    - name: IEEE
      icon: ai ai-doi
      link: https://doi.org/10.1109/ICASSP.2019.8683534
    - name: HAL
      icon: ai ai-open-access
      link: https://hal.archives-ouvertes.fr/hal-02160940v1
    - name: Code
      icon: fa fa-github
      link: https://github.com/Chutlhu/MIRAGE
    - name: Resources
      icon: fa fa-paperclip
      link: https://sigport.org/documents/mirage-2d-sound-source-localization-using-microphone-pair-augmentation-echoes
  resources_popup:
    - name: Bibtex
      icon: fa fa-quote-right
      text: >
        @inproceedings{DiCarlo2019mirage,
          arxiv = {1906.08968},
          author = { Di Carlo, Diego and Deleforge, Antoine and Bertin, Nancy},
          booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
          doi = {10.1109/ICASSP.2019.8683534},
          hal_id = {hal-01909531},
          keywords = {Image Microphones,Sound Source Localization,Supervised Learning,TDOA Estimation},
          pages = {775--779},
          title = {Mirage: 2D Source Localization Using Microphone Pair Augmentation with Echoes},
          url = {https://github.com/Chutlhu/MIRAGE},
          volume = {2019-May},
          year = {2019}
        }
    - name: Abstract
      icon: fa fa-align-left
      text: >
        It is commonly observed that acoustic echoes hurt performance of sound
        source localization (SSL) methods.
        We introduce the concept of microphone array augmentation with echoes (MIRAGE)
        and show how estimation of early-echo  characteristics can in fact benefit SSL.
        We propose a learning based scheme for echo estimation combined with a physics based
        scheme for echo aggregation.
        In a simple scenario involving 2 microphones close to a reflective surface and
        one source,
        we show using simulated data that the proposed approach performs similarly to
        a correlation-based method
        in azimuth estimation while retrieving elevation as well from 2 microphones only,
        an impossible task in anechoic settings.

- title: 'SEPARAKE: Source Separation with a Little Help from Echoes'
  id: separake
  booktitle: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  year: 2018
  author: Scheibler, Robin and Di Carlo, Diego and Deleforge, Antoine and Dokmanic, Ivan
  resources_link:
    - name: IEEE
      icon: ai ai-doi
      link: https://doi.org/10.1109/ICASSP.2018.8461345
    - name: arXiv
      icon: ai ai-open-access
      link: https://arxiv.org/abs/1711.06805
    - name: Code
      icon: fa fa-github
      link: https://github.com/fakufaku/separake
    - name: Resources
      icon: fa fa-paperclip
      link: https://sigport.org/documents/separake-source-separation-little-help-echoes
  resources_popup:
    - name: Bibtex
      icon: fa fa-quote-right
      text: >
        @inproceedings{Scheibler2017separake,
          arxiv = {1711.06805},
          author = {Scheibler, Robin and Di Carlo, Diego and Deleforge, Antoine and Dokmanic, Ivan},
          doi = {10.1109/ICASSP.2018.8461345},
          hal_id = {hal-01909531},
          journal = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
          keywords = {Echoes,Multi-channel,NMF,Room geometry,Source separation},
          pages = {6897--6901},
          title = {Separake: Source Separation with a Little Help from Echoes},
          url = {https://github.com/fakufaku/separake},
          year = {2018}
        }
    - name: Abstract
      icon: fa fa-align-left
      text: >
        It is commonly believed that multipath hurts various audio process-ing
        algorithms.At odds with this belief, we show that multipath in fact helps sound
        source separation,even with very simple propagation models.Unlike most existing
        methods, we neither ignore the room impulse responses, nor we attempt to estimate
        them fully. Weather  assume  that  we  know  the  positions  of  a  few  virtual
         micro-phones generated by echoes and we show how this gives us enough spatial
        diversity to get a performance boost over the anechoic case.We show improvements
        for two standard algorithms\u2014one that uses only magnitudes of the transfer
        functions, and one that also uses the phases.Concretely, we show that multichannel
        non-negative matrix factorization aided with a small number of echoes beats the
        vanilla variant of the same algorithm, and that with magnitude information only,
        echoes enable separation where it was previously impossible

- abstract: This short paper presents an efficient, flexible implementation of the
    SRP-PHAT  multichannel  sound  source  localization  method.   Themethod is evaluated
    on the single-source tasks of the LOCATA 2018development  dataset,  and  an  associated  Matlab  toolbox  is  madeavailable
    online
  arxiv: '1812.05901'
  author: Lebarbenchon, Romain and Camberlein, Ewen and Di Carlo, Diego and Deleforge,
    Antoine and Bertin, Nancy
  bibitem: "@inproceedings{Lebarbenchon2018, abstract = {This short paper presents\
    \ an efficient, flexible implementation of the SRP-PHAT  multichannel  sound \
    \ source  localization  method.   Themethod is evaluated on the single-source\
    \ tasks of the LOCATA 2018development  dataset,  and  an  associated  Matlab \
    \ toolbox  is  madeavailable online}, arxiv = {1812.05901}, author = {Lebarbenchon,\
    \ Romain and Camberlein, Ewen and Di Carlo, Diego and Deleforge, Antoine and Bertin,\
    \ Nancy}, booktitle = {LOCATA Challenge Workshop - a satellite event of International\
    \ Workshop on Acoustic Signal Enhancement (IWAENC)}, hal_id = {hal-02187964},\
    \ pages = {2--3}, title = {Evaluation of an Open-Source Implementation of the\
    \ Srp-Phat Algorithm Within the 2018 Locata Challenge}, year = {2018}}"
  booktitle: LOCATA Challenge Workshop - a satellite event of International Workshop
    on Acoustic Signal Enhancement (IWAENC)
  hal_id: hal-02187964
  title: Evaluation of an Open-Source Implementation of the SPR-PHAT Algorithm Within
    the 2018 Locata Challenge
  year: 2018

- abstract: 'Live concert recordings consist in long multitrack audio samples with
    significant interferences between channels.
    For audio engineering purposes, it is desirable to attenuate those interferences.
    Recently, we proposed an algorithm to this end based on Non-negative Matrix Factorization,
    that iteratively estimate the clean power spectral densities of the sources
    and the strength of each in each microphone signal, encoded in an interference
    matrix.
    Although it behaves well, this method is too demanding computationally
    for full-length concerts lasting more than one hour.
    In this paper, we show how random projections of the data can be leveraged
    for effective estimation of the parameters. Interference reduction with these
    ideas
    can be achieved on full-length live multi-track recordings in an acceptable
    time and could be used by sound engineers. We demonstrate the efficiency of this
    approach on
    real full-length live recordings from the Montreux Jazz Festival and also provide
    an implementation of the method.'
  id: mirapie
  author: Di Carlo, Diego and Liutkus, Antoine and Déguernel, Ken
  bibitem: "@inproceedings{DiCarlo2018mirapie, author = {Di Carlo, Diego and Liutkus,\
    \ Antoine and D{\\'e}guernel, Ken}, booktitle = {IEEE International Conference\
    \ on Acoustics, Speech and Signal Processing (ICASSP)}, doi = {10.1109/ICASSP.2018.8462621},\
    \ hal_id = {hal-01713889}, hal_verision = {v1}, keywords = {Compressive sensing,Interference\
    \ reduction,Microphone leakage,Random projection,Source separation}, pages =\
    \ {736--740}, title = {Interference reduction on full-length live recordings},\
    \ url = {https://github.com/Chutlhu/mirapie}, volume = {2018-April}, year\
    \ = {2018}}"
  booktitle: IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP)
  doi: 10.1109/ICASSP.2018.8462621
  hal_id: hal-01713889
  hal_verision: v1
  keywords: Compressive sensing,Interference reduction,Microphone leakage,Random projection,Source
    separation
  title: Interference reduction on full-length live recordings
  url: https://github.com/Chutlhu/mirapie
  volume: 2018-April
  year: 2018

- abstract: In live multitrack recordings, each voice is usually captured by dedicated
    close microphones. Unfortunately, it is also captured in practice by other microphones
    intended for other sources, leading to so-called "interferences". Reducing this
    interference is desirable because it opens new perspectives for the engineering
    of live recordings. Hence, it has been the topic of recent research in audio processing.
    In this paper, we show how a Gaussian probabilistic framework may be set up for
    obtaining good isolation of the target sources. Doing so, we extend several state-of-the
    art methods by fixing some heuristic parts of their algorithms. As we show in
    a perceptual evaluation on real-world multitrack live recordings, the resulting
    principled techniques yield improved quality.
  address: Erlangen, Germany
  author: Di Carlo, Diego and Déguernel, Ken and Liutkus, Antoine
  bibitem: "@inproceedings{DiCarlo2017, abstract = {In live multitrack recordings,\
    \ each voice is usually captured by dedicated close microphones. Unfortunately,\
    \ it is also captured in practice by other microphones intended for other sources,\
    \ leading to so-called \"interferences\". Reducing this interference is desirable\
    \ because it opens new perspectives for the engineering of live recordings. Hence,\
    \ it has been the topic of recent research in audio processing. In this paper,\
    \ we show how a Gaussian probabilistic framework may be set up for obtaining good\
    \ isolation of the target sources. Doing so, we extend several state-of-the art\
    \ methods by fixing some heuristic parts of their algorithms. As we show in a\
    \ perceptual evaluation on real-world multitrack live recordings, the resulting\
    \ principled techniques yield improved quality.}, address = {Erlangen, Germany},\
    \ author = {Di Carlo, Diego and D{\\'e}guernel, Ken and Liutkus, Antoine}, booktitle\
    \ = {AES International Conference on Semantic Audio}, hal_id = {hal-01515971},\
    \ hal_verision = {v1}, title = {Gaussian framework for interference reduction\
    \ in live recordings}, url = {https://github.com/Chutlhu/mirapie}, volume\
    \ = {22-24-June}, year = {2017}}"
  booktitle: AES International Conference on Semantic Audio
  hal_id: hal-01515971
  hal_verision: v1
  title: Gaussian framework for interference reduction in live recordings
  url: https://github.com/Chutlhu/mirapie
  year: 2017

- title: Gestural Control Of Wavefield synthesis
  author: Grani, Francesco and Di Carlo, Diego and Portillo, Jorge Madrid and Girardi,
    Matteo and Paisa, Razvan and Banas, Jian Stian and Vogiatzoglou, Iakovos and Overholt,
    Dan and Serafin, Stefania
  bibitem: "@inproceedings{Grani2016gestural, author = {Grani, Francesco and Di\
    \ Carlo, Diego and Portillo, Jorge Madrid and Girardi, Matteo and Paisa, Razvan\
    \ and Banas, Jian Stian and Vogiatzoglou, Iakovos and Overholt, Dan and Serafin,\
    \ Stefania}, booktitle = {Sound and Music Computing Conference (SMC)}, pages\
    \ = {185--192}, title = {Gestural Control Of Wavefield synthesis}, url = {https://vbn.aau.dk/ws/portalfiles/portal/244887082/2016_Gestural_Control_Of_Wavefield_synthesis_SMC2016.pdf},\
    \ year = {2016}}"
  booktitle: Sound and Music Computing Conference (SMC)
  url: https://vbn.aau.dk/ws/portalfiles/portal/244887082/2016_Gestural_Control_Of_Wavefield_synthesis_SMC2016.pdf
  year: 2016

- address: Venice
  author: Di Carlo, Diego and Rodá, Antonio
  bibitem: "@inproceedings{DiCarlo2014, address = {Venice}, author = {Di Carlo,\
    \ Diego and Rod{\\'a}, Antonio}, booktitle = {Proceedings of the 1st International\
    \ Workshop on Computer and Robotic Systems for Automatic Music Performance (SAMP\
    \ 14)}, pages = {1--8}, title = {Automatic music \u201Clistening\u201D for\
    \ automatic music performance: a grandpiano dynamics classifier,\u201D}, year\
    \ = {2014}}"
  booktitle: Proceedings of the 1st International Workshop on Computer and Robotic
    Systems for Automatic Music Performance (SAMP 14)
  title: "Automatic music \u201Clistening\u201D for automatic music performance: a\
    \ grandpiano dynamics classifier,\u201D"
  year: 2014

thesis:
- type: PhD
  author: Di Carlo, Diego
  advisor: Deleforge, Antione and Bertin, Nancy
  bibitem: >
   "@phdthesis{dicarlo2020echo,
    TITLE = {{Echo-aware signal processing for audio scene analysis}},
    AUTHOR = {Di Carlo, Diego},
    URL = {https://tel.archives-ouvertes.fr/tel-03133271},
    SCHOOL = {{UNIVERSIT{\'E} DE RENNES 1 ; INRIA - IRISA - PANAMA}},
    YEAR = {2020},
    MONTH = Dec,
    KEYWORDS = {Room Geometry Estimation ; Sound Source Localization ; Sound Source Separation ; Blind Channel Estimation ; Acoustic Echoes ; Traitement des signaux audio ; {\'e}chos acoustiques ; estimation des canaux aveugles ; s{\'e}para- tion de sources sonores ; localisation de sources sonores ; estimation de la g{\'e}om{\'e}trie d'une salle},
    TYPE = {Theses},
    PDF = {https://tel.archives-ouvertes.fr/tel-03133271/file/main.pdf},
    HAL_ID = {tel-03133271},
    HAL_VERSION = {v1},
    }"
  hal_id: tel-03133271
  hal_verision: v1
  keywords:
  link: https://tel.archives-ouvertes.fr/tel-03133271
  school: Université de Rennes 1 - Panama Team (INRIA/IRISA) [France]
  title: Echo-aware signal processing for audio scene analysis
  code: https://github.com/Chutlhu/manuscript
  url: https://tel.archives-ouvertes.fr/tel-03133271
  year: 2020
  abstract: >
    Most of audio signal processing methods regard reverberation and in particular acoustic echoes as a nuisance. However, they convey important spatial and semantic information about sound sources and, based on this, recent echo-aware methods have been proposed. In this work, we focus on two directions. First, we study how to estimate acoustic echoes blindly from microphone recordings. Two approaches are proposed, one leveraging on continuous dictionaries, one using recent deep learning techniques. Then, we focus on extending existing methods in audio scene analysis to their echo-aware forms. The Multichannel NMF framework for audio source separation, the SRP-PHAT localization method, and the MVDR beamformer for speech enhancement are all extended to their echo-aware versions.

- type: master
  author: Di Carlo, Diego
  advisor: Orio, Nicola and Liutkus, Antoine
  bibitem: "@mastersthesis{DiCarlo2017gaussian, author = {Di Carlo, Diego and Orio,\
    \ Nicola}, hal_id = {hal-01870918}, hal_verision = {v1}, keywords = {interference\
    \ reduction, microphone leakage, bleeding, source separation, random projection,\
    \ Non negative matrix factorisation NMF}, link = {http://tesi.cab.unipd.it/56327/},\
    \ school = {Universit{\\`a} degli Studi di Padova}, title = {Gaussian Framework\
    \ for Interference Reduction in Live Recordings}, url = {https://github.com/Chutlhu/mirapie},\
    \ year = {2017}}"
  hal_id: hal-01870918
  hal_verision: v1
  keywords: interference reduction, microphone leakage, bleeding, source separation,
    random projection, Non negative matrix factorisation NMF
  link: https://hal.inria.fr/hal-01870918
  school: Universitá degli Studi di Padova [Italy]
  title: Gaussian Framework for Interference Reduction in Live Recordings
  code: https://github.com/Chutlhu/mirapie
  url: http://tesi.cab.unipd.it/56327/
  year: 2017

- type: bachelor
  author: Di Carlo, Diego
  advisor: Antonio Rodá
  bibitem: "@mastersthesis{DiCarlo2014sequential, author = {Di Carlo, Diego}, school\
    \ = {Universit{\\`a} degli Studi di Padova}, title = {Sequential Feature Selection:\
    \ Algorithm and Applications for Audio Information Retrieval}, year = {2014}\
    }"
  school: Universitá degli Studi di Padova [Italy]
  title: 'Sequential Feature Selection: Algorithms and Applications for Audio Information
    Retrieval'
  year: 2014

other:
- title: Etude des propriétés acoustiques de la guitare Black Flag
  author: Denis Thouret, Loïc Le Marrec, Diego Di Carlo, Ewen Camberlein, Clements Gaultier and Frédéric Bimbot
  bibitem: >
    "@unknown{Thouret2010etude,
      author = {Thouret, Denis and Le Marrec, Loïc and Di Carlo, Diego and Camberlein, Ewen and Gaultier, Clement and Bimbot, Frédéric},
      year = {2019},
      month = {10},
      pages = {},
      title = {Etude des propriétés acoustiques de la guitare Black Flag},
      doi = {10.13140/RG.2.2.26251.03368}
    }"
  link: https://www.researchgate.net/publication/337328411_Etude_des_proprietes_acoustiques_de_la_guitare_Black_Flag
  link: https://www.ouest-france.fr/bretagne/rennes-35000/video-rennes-il-fabrique-une-guitare-unique-au-monde-en-materiaux-spatiaux-6366368
  link: https://jsm.irisa.fr/2018/06/27/la-harpe-electronique/
  doi: 10.13140/RG.2.2.26251.03368
  where: Journee Science et Musique, Rennes (Fr)
  year: 2018